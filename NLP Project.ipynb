{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('biomed.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>As biomedical information in the form of publications and electronic health records (EHR) increases at an increasingly fast pace there is clear utility in having systems that can automatically handle information extraction summarization and question answering tasks. While there have been signiﬁcant strides in improving language tasks for general language addressing domain-speciﬁc contexts still remains challenging. In this project I apply and ﬁne-tune models to the SQuAD dataset and further modify/adapt for biomedical domain-speciﬁc question answering. I evaluated and compared performance on the SQuAD dataset and BioASQ, a biomedical literature QA dataset, with the goal of analyzing and developing approaches to leverage unsupervised language models for domain-speciﬁc applications. Uponbgenerating various ﬁne-tuned models the best performance for general language SQuAD QA achieved score of 76 EM score of 73 and for biomedical-speciﬁc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [As biomedical information in the form of publications and electronic health records (EHR) increases at an increasingly fast pace there is clear utility in having systems that can automatically handle information extraction summarization and question answering tasks. While there have been signiﬁcant strides in improving language tasks for general language addressing domain-speciﬁc contexts still remains challenging. In this project I apply and ﬁne-tune models to the SQuAD dataset and further modify/adapt for biomedical domain-speciﬁc question answering. I evaluated and compared performance on the SQuAD dataset and BioASQ, a biomedical literature QA dataset, with the goal of analyzing and developing approaches to leverage unsupervised language models for domain-speciﬁc applications. Uponbgenerating various ﬁne-tuned models the best performance for general language SQuAD QA achieved score of 76 EM score of 73 and for biomedical-speciﬁc ]\n",
       "Index: []"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>As biomedical information in the form of publications and electronic health records (EHR) increases at an increasingly fast pace there is clear utility in having systems that can automatically handle information extraction summarization and question answering tasks. While there have been signiﬁcant strides in improving language tasks for general language addressing domain-speciﬁc contexts still remains challenging. In this project I apply and ﬁne-tune models to the SQuAD dataset and further modify/adapt for biomedical domain-speciﬁc question answering. I evaluated and compared performance on the SQuAD dataset and BioASQ, a biomedical literature QA dataset, with the goal of analyzing and developing approaches to leverage unsupervised language models for domain-speciﬁc applications. Uponbgenerating various ﬁne-tuned models the best performance for general language SQuAD QA achieved score of 76 EM score of 73 and for biomedical-speciﬁc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [As biomedical information in the form of publications and electronic health records (EHR) increases at an increasingly fast pace there is clear utility in having systems that can automatically handle information extraction summarization and question answering tasks. While there have been signiﬁcant strides in improving language tasks for general language addressing domain-speciﬁc contexts still remains challenging. In this project I apply and ﬁne-tune models to the SQuAD dataset and further modify/adapt for biomedical domain-speciﬁc question answering. I evaluated and compared performance on the SQuAD dataset and BioASQ, a biomedical literature QA dataset, with the goal of analyzing and developing approaches to leverage unsupervised language models for domain-speciﬁc applications. Uponbgenerating various ﬁne-tuned models the best performance for general language SQuAD QA achieved score of 76 EM score of 73 and for biomedical-speciﬁc ]\n",
       "Index: []"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Punctuations,numbers and converting into lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(input_string):\n",
    "    assert(type(input_string)==str)\n",
    "    cleaned = re.sub(r'[^a-zA-Z0-9]','numbr',input_string)\n",
    "    cleaned = input_string.replace('[^\\w\\s]',' ')\n",
    "    cleaned = input_string.lower()\n",
    "    \n",
    "    return ' '.join(\n",
    "        porter.stem(term)\n",
    "        for term in cleaned.split()\n",
    "        if term not in set(stop_words)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [as biomedical inform in the form of publication and electronic health records increase fast pace there is clear utiliti in systems that can automatic handle extraction summarization and question answer tasks While there have been signiﬁcant strides in improve language tasks for general language address contexts still remains challenge in this project and ﬁne tuned models to the squad dataset further modify biomedical domain speciﬁc question answer compared performance on the squad dataset and biosqua a biomedical literature dataset with the goal of analyze and develop approaches to unsupervised models for speciﬁc applications Upon generate various ﬁne tuned models the best performance for general language squad score of and for speciﬁc ]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "result = df[0:1].apply(preprocess_text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>as biomedical inform in the form of publication and electronic health records increase fast pace there is clear utiliti in systems that can automatic handle extraction summarization and question answer tasks While there have been signiﬁcant strides in improve language tasks for general language address contexts still remains challenge in this project and ﬁne tuned models to the squad dataset further modify biomedical domain speciﬁc question answer compared performance on the squad dataset and biosqua a biomedical literature dataset with the goal of analyze and develop approaches to unsupervised models for speciﬁc applications Upon generate various ﬁne tuned models the best performance for general language squad score of and for speciﬁc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [as biomedical inform in the form of publication and electronic health records increase fast pace there is clear utiliti in systems that can automatic handle extraction summarization and question answer tasks While there have been signiﬁcant strides in improve language tasks for general language address contexts still remains challenge in this project and ﬁne tuned models to the squad dataset further modify biomedical domain speciﬁc question answer compared performance on the squad dataset and biosqua a biomedical literature dataset with the goal of analyze and develop approaches to unsupervised models for speciﬁc applications Upon generate various ﬁne tuned models the best performance for general language squad score of and for speciﬁc ]\n",
       "Index: []"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In',\n",
       " 'Out',\n",
       " 'PorterStemmer',\n",
       " '_',\n",
       " '_10',\n",
       " '_11',\n",
       " '_12',\n",
       " '_13',\n",
       " '_18',\n",
       " '_19',\n",
       " '_20',\n",
       " '_24',\n",
       " '_3',\n",
       " '_4',\n",
       " '_5',\n",
       " '__',\n",
       " '___',\n",
       " '__builtin__',\n",
       " '__builtins__',\n",
       " '__doc__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " '_dh',\n",
       " '_i',\n",
       " '_i1',\n",
       " '_i10',\n",
       " '_i11',\n",
       " '_i12',\n",
       " '_i13',\n",
       " '_i14',\n",
       " '_i15',\n",
       " '_i16',\n",
       " '_i17',\n",
       " '_i18',\n",
       " '_i19',\n",
       " '_i2',\n",
       " '_i20',\n",
       " '_i21',\n",
       " '_i22',\n",
       " '_i23',\n",
       " '_i24',\n",
       " '_i25',\n",
       " '_i3',\n",
       " '_i4',\n",
       " '_i5',\n",
       " '_i6',\n",
       " '_i7',\n",
       " '_i8',\n",
       " '_i9',\n",
       " '_ih',\n",
       " '_ii',\n",
       " '_iii',\n",
       " '_oh',\n",
       " 'df',\n",
       " 'exit',\n",
       " 'get_ipython',\n",
       " 'nltk',\n",
       " 'pd',\n",
       " 'porter',\n",
       " 'preprocess_text',\n",
       " 'ps',\n",
       " 'quit',\n",
       " 're',\n",
       " 'result',\n",
       " 'stemming',\n",
       " 'stop_words',\n",
       " 'stopwords',\n",
       " 'string']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stemming\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(tokenized_text):\n",
    "    text = [ps.stem(word) for word in tokenized_text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>as biomedical inform in the form of publication and electronic health records increase fast pace there is clear utiliti in systems that can automatic handle extraction summarization and question answer tasks While there have been signiﬁcant strides in improve language tasks for general language address contexts still remains challenge in this project and ﬁne tuned models to the squad dataset further modify biomedical domain speciﬁc question answer compared performance on the squad dataset and biosqua a biomedical literature dataset with the goal of analyze and develop approaches to unsupervised models for speciﬁc applications Upon generate various ﬁne tuned models the best performance for general language squad score of and for speciﬁc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [as biomedical inform in the form of publication and electronic health records increase fast pace there is clear utiliti in systems that can automatic handle extraction summarization and question answer tasks While there have been signiﬁcant strides in improve language tasks for general language address contexts still remains challenge in this project and ﬁne tuned models to the squad dataset further modify biomedical domain speciﬁc question answer compared performance on the squad dataset and biosqua a biomedical literature dataset with the goal of analyze and develop approaches to unsupervised models for speciﬁc applications Upon generate various ﬁne tuned models the best performance for general language squad score of and for speciﬁc ]\n",
       "Index: []"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
